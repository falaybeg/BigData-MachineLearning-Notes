{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pair RDD Transformations\n",
    "PairRDD is which provides enables to applied transformation functions with key/value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark = SparkSession.builder \\\n",
    ".master(\"local[4]\")\\\n",
    ".appName(\"PairRDD\")\\\n",
    ".config(\"spark.executer.memory\",\"2g\")\\\n",
    ".config(\"spark.driver.memory\",\"2g\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Single PairRDD Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = [(\"Ali\",40),(\"Mehmet\",21),(\"Veli\", 26),(\"Ayse\",33),(\"Elif\",28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageRdd= sc.parallelize(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by age (by value) which are lower than 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mehmet', 21), ('Veli', 26), ('Elif', 28)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageRdd.filter(lambda key_value: key_value[1] < 30).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by name (by key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ali', 40)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageRdd.filter(lambda key_value: key_value[0] == \"Ali\").take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(1,2),(3,4),(3,6),(4,7),(5,8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReduceByKey calculates sum of key values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (3, 10), (4, 7), (5, 8)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduceByKey(lambda x,y: x + y).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupByKey it return a dataset of (K, Iterable<V>) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1af2e8>),\n",
       " (3, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1af160>),\n",
       " (4, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1af208>),\n",
       " (5, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1afeb8>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupByKey().take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1af710>),\n",
       " (3, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1afa20>),\n",
       " (4, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1af860>),\n",
       " (5, <pyspark.resultiterable.ResultIterable at 0x7f8e0b1af6a0>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is calculated according to key .  (key, (sum of value, quantity of key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rdd.combineByKey((lambda value: (value,1)), (lambda acc,value: (acc[0] + value, acc[1] +1)), (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (2, 1)), (3, (10, 2)), (4, (7, 1)), (5, (8, 1))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapValues() focuses only on value of keys and here multiplied with 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 20), (3, 40), (3, 60), (4, 70), (5, 80)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(lambda x: x*10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multiple PairRDD Transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize([(3,9),(3,11),(6,36)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtraction of two rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4), (1, 2), (4, 7), (5, 8), (3, 6)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.subtract(rdd2).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 36), (3, 11), (3, 9)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.subtract(rdd).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join two RDD values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, (4, 9)), (3, (4, 11)), (3, (6, 9)), (3, (6, 11))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rdd.join(rdd2).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rightOuterJoin() (key, (value, corresponding value))\n",
    "Right key calculated but it does not have corresponding value in right. Therefore it is written None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, (4, 9)), (3, (4, 11)), (3, (6, 9)), (3, (6, 11)), (6, (None, 36))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.rightOuterJoin(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leftOuterJoin() (key, (value, corresponding value))\n",
    "Left key calculated but it does not have corresponding value in left. Therefore it is written None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (2, None)),\n",
       " (3, (4, 9)),\n",
       " (3, (4, 11)),\n",
       " (3, (6, 9)),\n",
       " (3, (6, 11)),\n",
       " (4, (7, None)),\n",
       " (5, (8, None))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.leftOuterJoin(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It calculates all combination values of two Rdd (Key, Iterable < V >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f8e0b159748>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f8e0b159400>)),\n",
       " (3,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f8e0b1594a8>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f8e0b159160>)),\n",
       " (4,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f8e0b159470>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f8e0b159128>)),\n",
       " (5,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f8e0b159438>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f8e0b1590b8>)),\n",
       " (6,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f8e0b159278>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f8e0b159198>))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.cogroup(rdd2).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
